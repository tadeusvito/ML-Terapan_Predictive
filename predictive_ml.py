# -*- coding: utf-8 -*-
"""Predictive_ML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vVjsMiNfexah6Lhi9VFLJEBJLZN0JBHO

# Data Loading

Melakukan load terhadap dataset dan import pada library yang dibutuhkan
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns

# load the dataset
url = '/content/Updated_Hotel_Booking_Data.csv'
hotels = pd.read_csv(url)
hotels

"""Dataset terdiri dari 600 baris dan dilengkapi dengan 10 kolom yang merupakan fitur dari dataset. Fitur-fitur dalam dataset ini meliputi:
- **Hotel Rating**: Rating hotel berdasarkan penilaian pengguna.
- **Number of Nights**: Jumlah malam menginap.
- **Number of Guests**: Jumlah tamu yang menginap.
- **Room Type**: Tipe kamar yang dipesan.
- **Hotel Location**: Lokasi hotel.
- **Distance to Attractions**: Jarak hotel ke atraksi terdekat.
- **Season**: Musim saat pemesanan.
- **Hotel Facilities**: Fasilitas yang tersedia di hotel.
- **Booking Time**: Waktu pemesanan dalam jam.
- **Price per Night**: Harga per malam untuk menginap.

# Exploratory Data Analysis

Menampilkan informasi umum tentang dataset seperti jumlah baris, tipe data, dan jumlah nilai non-null pada setiap kolom.

## Deskripsi Variabel
"""

hotels.info()

"""Dari output terlihat bahwa:

**Tipe data object (fitur kategori):**

*   Hotel Location
*   Season
*   Hotel Facilities
*   Booking Time

**Tipe data int64 & float64 (fitur numerik):**

Hotel Rating

*   Hotel Rating
*   Number of Nights
*   Number of Guests
*   Room Type
*   Price per NIght
*   Distance to Attractions

"""

hotels.describe()

"""Menampilkan statistik deskriptif untuk fitur numerik di dataset seperti rata-rata, standar deviasi, nilai minimum, dan maksimum.

## Handling Missing Value
"""

hotels.isna().sum()

"""Hasil output diatas menunjukkan bahwa tidak ada nilai yang hilang (missing value) di setiap kolom dalam dataset. Keberadaan data yang lengkap ini sangat penting untuk analisis lebih lanjut, karena memastikan bahwa semua informasi terkait hotel, seperti rating, jumlah tamu, jenis kamar, lokasi, jarak ke atraksi, musim, fasilitas, waktu pemesanan, dan harga per malam, tersedia secara utuh. Dengan demikian, analisis dan pengambilan keputusan dapat dilakukan dengan lebih akurat dan efektif."""

zero_value = (hotels == 0).sum()
zero_value

"""Pada kolom Booking Time, terdapat beberapa nilai yang menunjukkan angka 0. Hal ini dianggap wajar, karena angka 0 terjadi pada hari pemesanan, menunjukkan bahwa hotel tersebut mungkin baru menerima pemesanan pada hari yang sama."""

hotels[hotels['Booking Time'] == 0]

"""## Handling Data Duplicate"""

duplicate_rows = hotels[hotels.duplicated()]

if not duplicate_rows.empty:
    print("Duplicate Rows:")
    print(duplicate_rows)
else:
    print("No duplicate rows found.")

"""Pada hasil output di atas menunjukkan bahwa tidak ada data yang memiliki isi duplikat sama dengan yang lainnya. Hal ini menandakan bahwa dataset yang digunakan telah bersih dari entri yang berulang, yang dapat mempengaruhi keakuratan model.

## Outliers
"""

rows, cols = 6, 4
fig, axes = plt.subplots(rows, cols, figsize=(20, 30))

# Iterasi untuk membuat boxplot pada setiap kolom int64
for i, column in enumerate(hotels.columns):
    row, col = divmod(i, cols)
    sns.boxplot(ax=axes[row, col], x=hotels[column])
    axes[row, col].set_title(f'Box Plot of {column}')

# Menghapus subplot yang tidak terpakai jika jumlah kolom lebih sedikit daripada jumlah subplot
for j in range(len(hotels.columns), rows * cols):
    fig.delaxes(axes.flatten()[j])

plt.tight_layout()
plt.show()

"""Dari analisis box plot pada dataset ini, dapat disimpulkan bahwa sebagian besar data terdistribusi dengan baik tanpa adanya outlier yang signifikan. Beberapa nilai ekstrem terdeteksi pada sebagian kecil data, namun tidak cukup mencolok untuk mempengaruhi validitas analisis atau model prediksi secara keseluruhan. Secara umum, distribusi data terlihat stabil, dengan rentang nilai yang terpusat dan terjaga. Meskipun demikian, beberapa nilai ekstrem perlu diperhatikan lebih lanjut untuk memastikan konsistensi dan akurasi dalam analisis lebih mendalam.

## Univariate Analysis

Univariate analysis bertujuan untuk memahami karakteristik masing-masing fitur
secara terpisah sebelum melakukan analisis lebih lanjut atau membangun model prediksi
"""

numerical_features = [
    'Hotel Rating', 'Number of Nights', 'Number of Guests', 'Distance to Attractions',
    'Booking Time', 'Price per Night'
]

categorical_features = [
    'Room Type', 'Hotel Location', 'Season', 'Hotel Facilities'
]

"""### Categorical Features"""

feature = categorical_features[0]
count = hotels[feature].value_counts()
percent = 100*hotels[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""**Insight:**

Dari grafik yang ditampilkan, dapat dilihat distribusi tipe kamar pada dataset ini. Tipe kamar Suite memiliki jumlah sampel terbesar, yaitu 205 dengan persentase 34,2%. Diikuti oleh Tipe kamar Single dengan 202 sampel (33,7%) dan Tipe kamar Double dengan 193 sampel (32,2%). Ini menunjukkan bahwa pembagian pemesanan kamar hampir merata antara ketiga jenis kamar, dengan sedikit lebih banyak pemesanan untuk tipe Suite dan Single dibandingkan dengan tipe Double.
"""

feature = categorical_features[1]
count = hotels[feature].value_counts()
percent = 100*hotels[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""**Insight:**

Grafik di atas menunjukkan distribusi data terkait lokasi hotel berdasarkan jumlah sampel dan persentase. Ketiga lokasi—Suburbs, City Center, dan Countryside—memiliki distribusi yang relatif seimbang, dengan sedikit perbedaan antara masing-masing. Suburbs memiliki jumlah sampel tertinggi (207) dan persentase terbesar (34.5%), diikuti oleh City Center (197 sampel, 32.8%) dan Countryside (196 sampel, 32.7%). Ini menunjukkan bahwa ada kecenderungan hampir seimbang dalam pemilihan lokasi hotel, meskipun Suburbs sedikit lebih dominan dalam hal jumlah sampel.
"""

feature = categorical_features[2]
count = hotels[feature].value_counts()
percent = 100*hotels[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""**Insight:**

Grafik di atas menunjukkan distribusi data berdasarkan musim, dengan dua kategori yaitu High Season dan Low Season. High Season memiliki jumlah sampel tertinggi (312) dan persentase terbesar (52%), sementara Low Season memiliki 288 sampel dan persentase 48%. Meskipun ada sedikit perbedaan antara keduanya, High Season memiliki sedikit lebih banyak sampel, yang mencerminkan sedikit lebih banyak aktivitas atau pengunjung selama musim tersebut.
"""

feature = categorical_features[3]
count = hotels[feature].value_counts()
percent = 100*hotels[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""**Insight:**  
Grafik di atas menunjukkan distribusi fasilitas hotel yang tersedia dalam dataset. Dari total 600 sampel, fasilitas yang paling banyak tersedia adalah Spa, dengan 129 entri atau 21,5% dari keseluruhan. Diikuti oleh Restaurant yang mencatat 124 entri (20,7%), dan Pool dengan 121 entri (20,2%). Fasilitas Free Wi-Fi juga cukup umum, dengan 118 entri (19,7%), sementara Gym menjadi fasilitas yang paling sedikit tersedia, dengan 108 entri (18,0%). Data ini menunjukkan bahwa Spa dan Restaurant adalah fasilitas yang paling diminati oleh hotel, yang dapat menjadi pertimbangan penting bagi pengelola hotel dalam meningkatkan daya tarik dan kepuasan tamu.

### Numerical Features
"""

hotels.hist(bins=50, figsize=(20,15))
plt.show()

"""**Insight:**


*   Hotel Rating: Sebagian besar hotel memiliki rating antara 3 hingga 5, dengan rating 4 menjadi yang paling umum. Ini menunjukkan bahwa banyak tamu cenderung memilih hotel dengan kualitas yang baik.
*   Booking Time: Waktu pemesanan bervariasi, dengan banyak pemesanan dilakukan dalam rentang 0 hingga 30 hari sebelum kedatangan. Ini menunjukkan bahwa tamu cenderung melakukan pemesanan dalam waktu dekat, mungkin karena fleksibilitas dalam perjalanan.
*   Number of Nights: Tamu cenderung menginap antara 1 hingga 14 malam, dengan frekuensi yang cukup merata. Ini menunjukkan bahwa ada variasi dalam durasi menginap, mungkin tergantung pada tujuan perjalanan.
*  Number of Guests: Jumlah tamu bervariasi, tetapi sebagian besar hotel tampaknya memiliki kapasitas untuk menampung lebih dari 2 tamu. Ini menunjukkan bahwa hotel mungkin lebih sering digunakan untuk kelompok atau keluarga.
*   Price per Night: Harga per malam menunjukkan distribusi yang bervariasi, dengan banyak hotel berada di kisaran harga 200 hingga 400. Ini menunjukkan adanya pilihan harga yang beragam, memungkinkan tamu untuk memilih sesuai anggaran mereka.
*   Distance to Attractions: Jarak ke atraksi bervariasi, dengan beberapa tamu memilih hotel yang lebih dekat ke pusat atraksi. Ini menunjukkan pentingnya lokasi dalam pemilihan hotel.

## Multivariate Analysis

### Categorical Features

Mengecek rata-rata price terhadap masing-masing fitur untuk mengetahui pengaruh fitur kategori terhadap price.
"""

import seaborn as sns
import matplotlib.pyplot as plt

# Menentukan kolom kategorikal
cat_features = hotels.select_dtypes(include='object').columns.to_list()

# Menentukan jumlah baris dan kolom secara dinamis
n_cols = 3  # Jumlah kolom dalam grid
n_rows = -(-len(cat_features) // n_cols)  # Hitung jumlah baris (ceiling division)

# Membuat grid subplots
fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(18, 5 * n_rows))
axes = axes.flatten()  # Meratakan grid untuk iterasi

# Membuat plot untuk setiap kolom kategorikal
for i, col in enumerate(cat_features):
    # Changed 'Price (£)' to 'Y_harga_unit'
    sns.barplot(
        x=col,
        y="Price per Night",  # Use the correct column name for price
        data=hotels,
        ax=axes[i],
        palette="Set3",
        ci=None  # Interval kepercayaan dihilangkan untuk kejelasan
    )
    axes[i].set_title(f"Rata-rata 'Price per Night' terhadap {col}", fontsize=12)
    axes[i].tick_params(axis='x', rotation=45)  # Membuat label x miring
    axes[i].set_xlabel('')
    axes[i].set_ylabel('Rata-rata Harga')

# Menghapus subplot kosong (jika ada)
for j in range(len(cat_features), len(axes)):
    fig.delaxes(axes[j])

# Menyesuaikan tata letak
plt.tight_layout()
plt.show()

"""**Insight:**
*   Room Type: Rata-rata harga untuk berbagai jenis kamar (Single, Suite, Double) tampak cukup seragam. Ini menunjukkan bahwa tidak ada perbedaan harga yang signifikan antara jenis kamar yang berbeda. Hal ini bisa berarti bahwa hotel tersebut memiliki strategi harga yang konsisten untuk semua jenis kamar.
*   Hotel Location: Rata-rata harga untuk lokasi hotel (Countryside, City Center, Suburbs) juga menunjukkan pola yang serupa. Ini menunjukkan bahwa lokasi tidak terlalu mempengaruhi harga, atau hotel mungkin memiliki kebijakan harga yang seragam di semua lokasi.
*   Season: Terdapat perbedaan yang jelas antara harga di musim tinggi dan musim rendah. Harga di musim tinggi lebih tinggi dibandingkan dengan musim rendah, yang sesuai dengan ekspektasi umum bahwa permintaan akan akomodasi meningkat selama musim puncak.
*   Hotel Facilities:Rata-rata harga untuk fasilitas hotel (Pool, Restaurant, Spa, Gym, Free Wi-Fi) menunjukkan variasi yang lebih besar. Fasilitas seperti Spa dan Gym mungkin menarik lebih banyak tamu, sehingga harga bisa lebih tinggi. Namun, semua fasilitas tampak memiliki harga yang relatif seimbang, menunjukkan bahwa hotel mungkin menawarkan nilai yang baik untuk berbagai fasilitas.

### Numerical Features
"""

sns.pairplot(hotels, diag_kind = 'kde')

"""**Insight:**
*   Kualitas vs. Harga: Tamu cenderung memilih hotel dengan rating lebih tinggi meskipun harganya lebih mahal.
*   Durasi Menginap: Banyak tamu memilih untuk menginap dalam waktu singkat, tetapi ada juga yang merencanakan perjalanan jauh-jauh hari.
*   Variasi Harga: Harga per malam bervariasi secara signifikan, dan ini mungkin dipengaruhi oleh rating hotel dan waktu pemesanan.




"""

numerical_features = [col for col in numerical_features if col in hotels.columns]

plt.figure(figsize=(10, 8))
correlation_matrix = hotels[numerical_features].corr(method='spearman').round(2)

# Untuk menampilkan nilai di dalam kotak
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title("Correlation Matrix untuk Fitur Numerik", size=20)
plt.show()

"""**Insight:**


1.   **Korelasi Positif Kuat:**
*   Terdapat korelasi positif yang kuat (nilai korelasi mendekati 1) antara "Number of Nights" dan "Price per Night". Ini menunjukkan bahwa semakin lama tamu menginap, semakin tinggi harga per malamnya.
*   Juga terdapat korelasi positif yang kuat antara "Booking Time" dan "Price per Night". Ini mengindikasikan bahwa pemesanan yang dilakukan lebih awal cenderung memiliki harga per malam yang lebih tinggi.

2.   **Korelasi Positif Sedang:**
*   Terdapat korelasi positif sedang (nilai korelasi sekitar 0,5-0,7) antara "Number of Guests" dan "Number of Nights", serta "Number of Guests" dan "Price per Night". Ini menunjukkan bahwa semakin banyak tamu, semakin lama mereka menginap dan semakin tinggi harga per malamnya.


3.  **Korelasi Negatif Lemah:**
*  Terdapat korelasi negatif lemah (nilai korelasi sekitar -0,2) antara "Hotel Rating" dan "Number of Nights", serta "Hotel Rating" dan "Number of Guests". Ini mengindikasikan bahwa hotel dengan rating lebih tinggi cenderung memiliki tamu yang menginap lebih singkat dan dengan jumlah tamu yang lebih sedikit.


4.   **Korelasi Hampir Nol:**
*   Korelasi antara "Distance to Attractions" dan sebagian besar variabel lainnya mendekati nol. Ini menunjukkan bahwa jarak ke atraksi tidak memiliki hubungan yang signifikan dengan variabel-variabel lain dalam dataset.

## Menambahkan Fitur

Menambahkan fitur baru yang merepresentasikan interaksi antara beberapa fitur dapat membantu meningkatkan pemahaman tentang hubungan kompleks yang mempengaruhi harga. Dengan mengeksplorasi kombinasi dan rasio antar fitur, kita dapat mengungkap pola-pola yang sebelumnya tidak terlihat, sehingga dapat meningkatkan kemampuan memprediksi atau menjelaskan harga secara lebih akurat
"""

# Membuat fitur baru berdasarkan interaksi antara beberapa fitur
hotels['Nights_Guests_Interaction'] = hotels['Number of Nights'] * hotels['Number of Guests']
hotels['Distance_Booking_Ratio'] = hotels['Distance to Attractions'] / (hotels['Booking Time'] + 1)  # Untuk menghindari pembagian dengan 0

# Menghitung korelasi kembali setelah penambahan fitur baru
new_numerical_features = numerical_features + ['Nights_Guests_Interaction', 'Distance_Booking_Ratio']

# Menghitung matriks korelasi
correlation_matrix_new = hotels[new_numerical_features].corr()

# Visualisasi korelasi dalam bentuk heatmap yang baru
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix_new, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
plt.title('Updated Correlation Matrix untuk Fitur Numerik', fontsize=14)
plt.show()

"""**Insight**

1. **Korelasi Positif yang Kuat:**  
   - **Number of Nights dan Price per Night** memiliki korelasi yang sangat tinggi (0.86), menunjukkan bahwa semakin banyak malam yang dipesan, semakin tinggi harga per malam yang dikenakan. Ini mungkin mencerminkan kebijakan harga yang lebih tinggi untuk pemesanan jangka panjang.  
   - **Number of Guests** juga menunjukkan korelasi positif yang signifikan dengan **Number of Nights (0.73)** dan **Price per Night (0.85)**, menunjukkan bahwa pemesanan untuk lebih banyak tamu cenderung berlangsung lebih lama dan dengan harga yang lebih tinggi.  

2. **Korelasi Negatif:**  
   - **Booking Time dan Distance Booking Ratio** memiliki korelasi negatif yang cukup kuat (-0.52), menunjukkan bahwa semakin jauh waktu pemesanan dari tanggal kedatangan, semakin kecil kemungkinan tamu memilih hotel yang jauh dari atraksi. Ini menunjukkan bahwa tamu lebih cenderung memesan hotel yang dekat dengan atraksi saat mereka melakukan pemesanan mendekati waktu kedatangan.  

3. **Korelasi Lemah:**  
   - Sebagian besar fitur lainnya menunjukkan korelasi yang lemah, dengan nilai di sekitar 0.1 hingga 0.3. Misalnya, **Hotel Rating dan Distance to Attractions** memiliki korelasi positif yang sangat rendah (0.05), menunjukkan bahwa tidak ada hubungan yang signifikan antara rating hotel dan jarak ke atraksi.  

4. **Interaksi Tamu dan Malam:**  
   - **Nights_Guests_Interaction** menunjukkan korelasi positif dengan **Number of Nights (0.63)** dan **Number of Guests (0.63)**, yang menunjukkan bahwa interaksi antara jumlah malam dan jumlah tamu berkontribusi pada pemesanan yang lebih lama dan lebih banyak tamu.

#Data Preparation

##Encode Fitur Kategori
"""

from sklearn.preprocessing import OneHotEncoder

# Check if categorical columns exist before applying one-hot encoding
categorical_features = ['Room Type', 'Hotel Location', 'Season', 'Hotel Facilities']
existing_categorical_features = [col for col in categorical_features if col in hotels.columns]

# Apply one-hot encoding only to existing categorical features
for feature in existing_categorical_features:
    hotels = pd.concat([hotels, pd.get_dummies(hotels[feature], prefix=feature)], axis=1)

# Drop original categorical columns that were encoded
hotels.drop(existing_categorical_features, axis=1, inplace=True, errors='ignore')

hotels.head()

"""##PCA

Mengamati hubungan antara fitur numerik Number of Nights dan Nights Guests Interaction menggunakan fungsi pairplot()
"""

sns.pairplot(hotels[['Number of Nights','Nights_Guests_Interaction']], plot_kws={"s": 2});

from sklearn.decomposition import PCA

pca = PCA(n_components=2, random_state=123)
pca.fit(hotels[['Number of Nights','Nights_Guests_Interaction']])
princ_comp = pca.transform(hotels[['Number of Nights','Nights_Guests_Interaction']])

"""PCA untuk mereduksi dimensi dari dua fitur 'Number of Nights' dan 'Nights_Guests_Interaction'"""

pca.explained_variance_ratio_.round(2)

"""Variansi yang dijelaskan oleh masing-masing komponen utama"""

from sklearn.decomposition import PCA
pca = PCA(n_components=1, random_state=123)
pca.fit(hotels[['Number of Nights','Nights_Guests_Interaction']])
hotels['Efficiency'] = pca.transform(hotels.loc[:, ('Number of Nights','Nights_Guests_Interaction')]).flatten()
hotels.drop(['Number of Nights','Nights_Guests_Interaction'], axis=1, inplace=True)

"""Melakukan PCA untuk mengurangi dimensi data pada fitur 'Number of Nights' dan 'Nights_Guests_Interaction' menjadi satu fitur baru, yaitu 'Efficiency'. Kemudian menghapus kolom yang tidak lagi diperlukan."""

hotels.head()

"""## Train Test Split"""

from sklearn.model_selection import train_test_split

X = hotels.drop(["Price per Night"],axis =1)
y = hotels["Price per Night"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 123)

"""Dataset dibagi menjadi data latih (train) dan data uji (test) dengan proporsi 80:20 menggunakan fungsi train_test_split dari scikit-learn. Ini penting untuk melatih model dengan data latih dan menguji performanya dengan data uji."""

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""## Standarisasi"""

from sklearn.preprocessing import StandardScaler

# Update numerical_features to exclude dropped columns
numerical_features = [
    'Hotel Rating', 'Number of Guests', 'Distance to Attractions',
    'Booking Time', 'Distance_Booking_Ratio', 'Efficiency'  # Include 'Efficiency' if it's a numerical feature
]

scaler = StandardScaler()

# Select only the existing numerical features for scaling
scaler.fit(X_train[numerical_features])
X_train[numerical_features] = scaler.transform(X_train.loc[:, numerical_features])

X_train[numerical_features].head()

"""Standarisasi dilakukan pada fitur numerik untuk memastikan bahwa setiap fitur memiliki rata-rata 0 dan variansi 1. Hal ini penting agar model tidak terpengaruh oleh perbedaan skala antar fitur, terutama ketika menggunakan algoritma berbasis jarak seperti KNN."""

X_train[numerical_features].describe().round(3)

""":Menampilkan deskripsi statistik dari data latih yang sudah distandarisasi, seperti pada mean pada tiap-tiap kolom numerik yang menjadi 0 dan variansi menjadi 1

# Model Development
"""

# Siapkan dataframe untuk analisis model
models = pd.DataFrame(index=['train_mse', 'test_mse'],
                      columns=['KNN', 'RandomForest', 'Boosting'])

"""Membuat 3 Model Machine Learning dengan algoritma KNN, Random Forest, dan Ada Boost

## KNN Model
"""

from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error

knn = KNeighborsRegressor(n_neighbors=13)
knn.fit(X_train, y_train)

models.loc['train_mse','knn'] = mean_squared_error(y_pred = knn.predict(X_train), y_true=y_train)

"""Membuat model KNN (K-Nearest Neighbors) untuk prediksi harga  hotel. Model ini menggunakan parameter n_neighbors=13, yang berarti menggunakan 13 tetangga terdekat untuk menentukan prediksi harga.

## Random Forest Model
"""

# Impor library yang dibutuhkan
from sklearn.ensemble import RandomForestRegressor

# buat model prediksi
RF = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=55, n_jobs=-1)
RF.fit(X_train, y_train)

models.loc['train_mse','RandomForest'] = mean_squared_error(y_pred=RF.predict(X_train), y_true=y_train)

"""Membuat model Random Forest untuk prediksi harga hotel. Random Forest menggabungkan banyak pohon keputusan untuk meningkatkan akurasi prediksi.

## Ada Boosting Model
"""

from sklearn.ensemble import AdaBoostRegressor

boosting = AdaBoostRegressor(n_estimators=250,
                             learning_rate=0.01,
                             random_state=50)

boosting.fit(X_train, y_train)
models.loc['train_mse','Boosting'] = mean_squared_error(y_pred=boosting.predict(X_train), y_true=y_train)

"""Membuat model AdaBoost untuk meningkatkan kinerja model dengan menggunakan teknik boosting. AdaBoost menggabungkan beberapa model lemah menjadi model yang lebih kuat.

# Evaluasi
"""

X_test[numerical_features] = scaler.transform(X_test.loc[:, numerical_features])
X_test[numerical_features].head()

"""Melakukan proses scaling pada data latih untuk menghindari kebocoran data"""

# Buat variabel mse yang isinya adalah dataframe nilai mse data train dan test pada masing-masing algoritma
mse = pd.DataFrame(columns=['train', 'test'], index=['KNN','RF','Boosting'])

# Buat dictionary untuk setiap algoritma yang digunakan
model_dict = {'KNN': knn, 'RF': RF, 'Boosting': boosting}

# Hitung Mean Squared Error masing-masing algoritma pada data train dan test
for name, model in model_dict.items():
    mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))/1e3
    mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))/1e3

# Panggil mse
mse

"""Menghitung Mean Squared Error (MSE) untuk masing-masing model pada data latih dan uji untuk membandingkan kinerja model.

"""

fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

"""**Insight**

Grafik di atas menunjukkan perbandingan error antara tiga model: **KNN**, **Random Forest (RF)**, dan **Boosting**. Grafik ini membandingkan nilai error pada data latih (train) dan data uji (test) untuk masing-masing model.

- **KNN (K-Nearest Neighbors)**:
  - Model KNN menunjukkan nilai error yang cukup besar pada data uji (test) dibandingkan dengan data latih (train). Ini menunjukkan bahwa model KNN cenderung mengalami overfitting, di mana performanya lebih baik pada data latih dibandingkan dengan data uji.
  
- **Random Forest (RF)**:
  - Model Random Forest menunjukkan nilai error yang relatif kecil baik pada data latih maupun data uji. Hal ini menandakan bahwa Random Forest memiliki kemampuan yang baik dalam generalisasi, yaitu menghasilkan prediksi yang akurat baik pada data latih maupun data uji.
  
- **Boosting**:
  - Model Boosting menunjukkan error yang cukup besar pada data latih dan data uji, meskipun lebih rendah pada data latih. Meskipun algoritma Boosting dapat meningkatkan akurasi prediksi, model ini tampaknya tidak lebih unggul dibandingkan dengan Random Forest dalam hal performa pada data uji.

Secara keseluruhan, **Random Forest** menunjukkan performa terbaik di antara ketiga model dalam hal akurasi prediksi pada data uji dan data latih.

"""

prediksi = X_test.iloc[:10].copy()
pred_dict = {'y_true':y_test[:10]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)

pd.DataFrame(pred_dict)

"""Membandingkan hasil prediksi dari tiga model (KNN, Random Forest, dan Boosting) pada 10 sampel pertama data uji.




"""

gridtuning = pd.DataFrame(index=['KNN', 'RF', 'Adaboost'], columns=['train_mse', 'test_mse'])

"""Untuk meningkatkan performa model, dilakukan Hyperparameter Tuning menggunakan Grid Search, sebuah teknik sistematis untuk menguji kombinasi parameter tertentu guna menemukan konfigurasi terbaik"""

from sklearn.model_selection import GridSearchCV

param_grid_knn = {
    'n_neighbors': [3, 5, 7, 9, 11, 13, 15]
}

knn = KNeighborsRegressor()

grid_search_knn = GridSearchCV(knn, param_grid_knn, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)
grid_search_knn.fit(X_train, y_train)

gridtuning.loc['KNN', 'train_mse'] = mean_squared_error(y_pred=grid_search_knn.predict(X_train), y_true=y_train)
gridtuning.loc['KNN', 'test_mse'] = mean_squared_error(y_pred=grid_search_knn.predict(X_test), y_true=y_test)

"""GridSearchCV digunakan untuk mencari kombinasi terbaik dari hyperparameter n_neighbors pada model KNN. Proses ini dilakukan dengan validasi silang (5-fold cross-validation) untuk memastikan bahwa model tidak overfit."""

param_grid_rf = {
    'n_estimators': [10, 50, 100, 200],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10]
}

rf = RandomForestRegressor(random_state=35, n_jobs=-1)

grid_search_rf = GridSearchCV(rf, param_grid_rf, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)
grid_search_rf.fit(X_train, y_train)

gridtuning.loc['RF', 'train_mse'] = mean_squared_error(y_pred=grid_search_rf.predict(X_train), y_true=y_train)
gridtuning.loc['RF', 'test_mse'] = mean_squared_error(y_pred=grid_search_rf.predict(X_test), y_true=y_test)

"""GridSearchCV digunakan untuk mencari kombinasi terbaik dari hyperparameter n_estimators, max_depth, dan min_samples_split pada model Random Forest."""

param_grid_ada = {
    'n_estimators': [50, 100, 200, 300],
    'learning_rate': [0.01, 0.1, 1.0]
}

ada = AdaBoostRegressor(random_state=42)

grid_search_ada = GridSearchCV(ada, param_grid_ada, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)
grid_search_ada.fit(X_train, y_train)

gridtuning.loc['Adaboost', 'train_mse'] = mean_squared_error(y_pred=grid_search_ada.predict(X_train), y_true=y_train)
gridtuning.loc['Adaboost', 'test_mse'] = mean_squared_error(y_pred=grid_search_ada.predict(X_test), y_true=y_test)

"""GridSearchCV digunakan untuk mencari kombinasi terbaik dari hyperparameter n_estimators dan learning_rate pada model AdaBoost."""

gridtuning

"""Menampilkan DataFrame gridtuning yang berisi nilai MSE untuk data latih dan uji masing-masing model setelah tuning hyperparameter."""

fig, ax = plt.subplots()
gridtuning.sort_values(by='test_mse', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

"""**Insight dari Grafik Setelah Tuning**

Grafik di atas menunjukkan perbandingan **Mean Squared Error (MSE)** untuk tiga model yang digunakan, yaitu **Random Forest (RF)**, **AdaBoost**, dan **KNN**, baik pada data latih (train) maupun data uji (test) setelah dilakukan tuning.

- **Random Forest (RF)**:
  - Setelah tuning, model Random Forest menunjukkan nilai **MSE** yang lebih rendah pada data uji (test) dibandingkan dengan data latih (train). Hal ini menandakan bahwa model Random Forest memiliki kemampuan yang baik untuk menggeneralisasi pada data uji dan memberikan prediksi yang akurat setelah tuning.

- **AdaBoost**:
  - Model AdaBoost juga mengalami penurunan nilai **MSE** pada data latih dan data uji setelah tuning, namun nilai **MSE** pada data uji masih lebih tinggi dibandingkan dengan Random Forest. Meskipun demikian, model ini menunjukkan perbaikan dalam akurasi setelah dilakukan tuning.

- **KNN (K-Nearest Neighbors)**:
  - Model KNN setelah tuning menunjukkan **MSE** yang sangat besar baik pada data latih maupun data uji, dengan perbedaan yang cukup signifikan antara keduanya. Ini menunjukkan bahwa model KNN tidak terlalu berhasil dalam memprediksi harga hotel setelah dilakukan tuning, dan mungkin mengalami overfitting pada data latih.

Secara keseluruhan, **Random Forest** masih menjadi model terbaik setelah tuning, dengan performa yang lebih stabil dan lebih baik pada data uji, diikuti oleh AdaBoost dan KNN yang memiliki nilai **MSE** yang lebih tinggi.

"""

prediksi = X_test.iloc[:10].copy()
pred_dict = {'y_true':y_test[:10]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)

pd.DataFrame(pred_dict)

"""Prediksi dari Random Forest (RF) memberikan hasil yang terbaik, dengan nilai prediksi yang paling mendekati y_true, menunjukkan bahwa RF memiliki akurasi yang lebih tinggi dibandingkan model lainnya."""